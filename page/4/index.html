<!DOCTYPE html>
<html>
<head>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>


    
        <link rel="alternate" type="application/rss+xml" title="RSS" href="https://evanlyu732.github.io/atom.xml">
    
    
    
        
    
    
    
    
    
    
        
    
    
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
    <title>evan lyu</title>
    <meta charset="utf-8">
    <meta name="title" content="evan lyu">
    <meta name="description" content="">
    <meta property="og:image:width" content="200" />
    <meta property="og:image:height" content="200" />
    <link rel="stylesheet" href="https:&#x2F;&#x2F;evanlyu732.github.io/style.css">
    
    
    <style>
    @media screen and (min-width: 320px) {
        body {
            font-size: calc(16px + 2 * ((100vw - 320px) / 960));
        }
    }
    </style>
    
    <link rel="stylesheet" href="https://fonts.loli.net/css2?family=Source+Serif+Pro:wght@400;700&display=swap">
    <link rel="stylesheet" href="https://fonts.loli.net/css2?family=Noto+Serif+SC:wght@400;700&display=swap">
    <style>body { font-family: 'Source Serif Pro', 'Source Han Serif SC', 'Noto Serif CJK SC', 'Noto Serif SC', serif }</style>
    
</head>
<body>
    
    <header class="header">
        <div class="blog-title"><a href="https:&#x2F;&#x2F;evanlyu732.github.io" class="logo">evan lyu</a></div>
        <nav class="navbar">
    <ul class="menu">
        
        
        <li class="menu-item">
            
            
            
            
            <a href="https:&#x2F;&#x2F;evanlyu732.github.io&#x2F;" class="current-menu-item-link">主页</a>
            
        </li>
        
        <li class="menu-item">
            
            
            
            
            <a href="https:&#x2F;&#x2F;evanlyu732.github.io&#x2F;archives" class="menu-item-link">归档</a>
            
        </li>
        
        <li class="menu-item">
            
            
            
            
            <a href="https:&#x2F;&#x2F;evanlyu732.github.io&#x2F;about" class="menu-item-link">关于</a>
            
        </li>
        
        <li class="menu-item">
            
            
            
            
            <a href="https:&#x2F;&#x2F;evanlyu732.github.io&#x2F;note" class="menu-item-link">书架</a>
            
        </li>
        
        <li class="menu-item">
            
            
            
            
            <a href="https:&#x2F;&#x2F;evanlyu732.github.io&#x2F;atom.xml" class="menu-item-link">订阅</a>
            
        </li>
        
    </ul>
</nav>

    </header>
    
    <main class="main">
        
<section class="posts">
    
    <article class="post">
        <div class="post-title"><a href="https:&#x2F;&#x2F;evanlyu732.github.io&#x2F;blog20&#x2F;" class="post-title-link">一次对LLM时代下的工作流的思想实验</a></div>
        <div class="post-content">
            
                <blockquote>
<p>这篇文章是我对LLM时代下的工作流做的一次思想实验.</p>
</blockquote>
<p>首先明确一下共同语境, 日常工作的目的就是去解决特定问题. 要去解决问题可能需要物理空间上的移动, 比如网约车, 开会, 摆摊. 也可能不需要. LLM是个很强大的&quot;工具&quot;. 通过提问可以获得答案. 不同程度的LLM能给出来的答案质量也不同. 假设GPT5真的能达到博士水平. 那么有没有可能一个八岁小孩可以解决专家才能解决的问题呢? 或者说, 在不需要创造力的工作语境下, 可以解决大部分普通的工作内容呢? </p>
<p>现在让我们站在LLM的角度下, LLM只能接受提示词(提问). 而小孩和专家的区别, 在于提出的问题质量. 专家由于有足够的先验, 一般是不需要提问的, 并且提问的深度肯定越超八岁小孩. 八岁小孩由于没有先验知识和经验, 所以只能通过提问的方式获得答案. 如果一个<strong>小孩可以和专家提出一样的问题</strong>, 那么对于LLM来说小孩和专家也是一样的. <strong>一个问题可以由一系列的提问得到解决方案</strong>. 而小孩可以提出这一系列问题的话, 小孩就能够解决专家能解决的问题. (假设问题不需要高超的物理空间上的移动, 比如运动员, 飞行员等)</p>
<p>所以如何让小孩提出这一系列的问题呢? 核心思想是范围缩减.</p>
<p>Step1. 描述当前场景所要解决的问题. 让LLM提供大致的解决方案.</p>
<p>Step2.1. 假如LLM给出的大致的解决方案脱离了当前场景, 没有实际意义的话. 补充当前场景的先验描述. 重新提问. 进入到Step2.2</p>
<p>Step2.2. 遍历LLM提供大致的解决方案, 进行步骤拆解</p>
<p>Step3. 对于给定的步骤, 如果不能action的话, 提问LLM直到能够action为止. </p>
<p>Step4. 如果Step3给出来的步骤不能action, 说明缺少先验证描述. 补充当前场景的先验描述. 重新提问. 进入到Step2.1</p>
<p>Step5. 对Step3给出的步骤进行action. 问题解决.</p>
<p>相当于人是LLM的agent. 这时候LLM相当于人的大脑. 而提问就是交互方式. 很明显小孩需要提非常非常多的问题才能够完成任务, 在时间有限的条件下, 效率还是非常低的. </p>

            
        </div>
        <div class="post-meta">
            
                


二〇二四年七月廿七日

            
        </div>
    </article>
    
    <article class="post">
        <div class="post-title"><a href="https:&#x2F;&#x2F;evanlyu732.github.io&#x2F;blog19&#x2F;" class="post-title-link">热力学第二定律</a></div>
        <div class="post-content">
            
                <h1 id="qian-yan">前言</h1>
<p>在<a href="https://en.wikipedia.org/wiki/From_Eternity_to_Here">&quot;From Eternity to Here&quot;</a>, 一本研讨时间为什么是单向而不是双向的书里(aka. 时间之箭), 看到了这样一个观点, 大致的中文意思是&quot;如果你只能选择相信一条物理定律, 那一定是热力学第二定律.&quot;. </p>
<p>what? 难道不是万有引力之类的定律吗? 为什么热力学第二定律会有那么大的影响力? 以及现在流行说的&quot;熵增&quot;到底是什么? 现在让我们重温一下热力学第二定律的发展史.</p>
<h1 id="zheng-wen">正文</h1>
<p>下面这张图展示了热力学发展历史历程中的关键人物. 图片来自<a href="https://writings.stephenwolfram.com/2023/01/how-did-we-get-here-the-tangled-history-of-the-second-law-of-thermodynamics/">&quot;How Did We Get Here? The Tangled History of the Second Law of Thermodynamics&quot;</a>. 如果对热力学历史感兴趣强烈推荐阅读原文.</p>
<img src="https://raw.githubusercontent.com/EvanLyu732/evanlyu732.github.io/main/static/images/history.png" height="100" width="100"/>
<p>简而言之, 卡诺(Sadi Carnot)提出了卡诺热机(aka. 永动机), 但是卡诺的著作在他的时代不受待见. 直到去世后, 开尔文(Lord Kelvin)通过卡诺学弟整理的资料了解了卡诺的研究, 开尔文在卡诺热机的基础上提出了<a href="https://thermodynamics.dlut.edu.cn/fazhanjianshi/relixuesidadinglv.htm">热力学的另一种说法</a>. 而克劳修斯(Rudolf Julius Emmanuel Clausius)在此基础上提出了熵(entropy)的概念. 并且正式确立(formalization)了热力学第二定律的描述.</p>
<img src="https://raw.githubusercontent.com/EvanLyu732/evanlyu732.github.io/main/static/images/entropy.png" height="100" width="100"/>
<p>此外, 克劳修斯在提出热力学第二定律时, 将范围放大到了宇宙(universe). </p>
<img src="https://raw.githubusercontent.com/EvanLyu732/evanlyu732.github.io/main/static/images/uni_entropy.png" height="100" width="100"/>
<p>至此, 也就有所谓的热寂(Heat death of the universe)假说.</p>
<p>ok, 现在回到我们默认所说的&quot;熵增&quot;. 现在口语语境中的&quot;熵增&quot;默认代表的是混乱度. 克劳修斯最开始提出的熵的概念是两个热系统进行能量传输时所损失掉的能量. 不过确实直接的影响是, 既然无用能量增加了, 系统混乱度会随着时间的推移而增加. 因此理解成混乱度没有什么问题.</p>
<p>很有意思的是, Stephen Wolfram对热力学第二定律的理解. Stephen Wolfram以rule30元胞自动机举例. 简单的规则不断演变最终导致了整体系统复杂性增加. 这里有一点, Stephen Wolfram说的复杂性表现为混论度, 但是不太一样. 复杂性是站在观察者的视角上看得, 而混乱度是站在系统内部的视角上. 我们先继续往下走, 有意思的事来了.
Wolfram说宇宙就像一台超级超级计算机, 由于人类的计算能力始终跟不上宇宙. 因此, 复杂度总是增加的(宇宙运算不会停止). 但是假如人类的计算能力跟上了, 那么理论上给定人类所有的先验宇宙定律, 随便在路边找一块石头. 都能够推算出现在时刻到宇宙大爆炸之间甚至之前的事.</p>
<p>Which means, if 宇宙是有意识的. 算命和占卜是科学不是迷信. 自由意志也不存在. Really interesting.</p>
<h1 id="can-kao-zi-liao">参考资料</h1>
<ul>
<li><a href="https://writings.stephenwolfram.com/2023/02/computational-foundations-for-the-second-law-of-thermodynamics/">Computational Foundations for the Second Law of Thermodynamics</a></li>
<li><a href="https://writings.stephenwolfram.com/2023/01/how-did-we-get-here-the-tangled-history-of-the-second-law-of-thermodynamics/">How Did We Get Here? The Tangled History of the Second Law of Thermodynamics</a></li>
<li><a href="https://en.wikipedia.org/wiki/History_of_entropy">History of entropy</a></li>
<li><a href="http://hsiaoscu.pbworks.com/w/file/fetch/69026626/%E7%86%B1%E5%8A%9B%E5%AD%B8%E7%99%BC%E5%B1%95%E7%B0%A1%E5%8F%B2.pdf">熱力學發展簡史</a></li>
<li><a href="https://www.livescience.com/50941-second-law-thermodynamics.html">What is the second law of thermodynamics?</a></li>
</ul>

            
        </div>
        <div class="post-meta">
            
                


二〇二四年七月廿四日

            
        </div>
    </article>
    
    <article class="post">
        <div class="post-title"><a href="https:&#x2F;&#x2F;evanlyu732.github.io&#x2F;blog17&#x2F;" class="post-title-link">机器人大小脑调研</a></div>
        <div class="post-content">
            
                <p>人形机器人肯定算是这两年来最火的一个方向了, 大模型的出现让人型机器人落地有了曙光. 
目前往往有争议的是假如人形机器人真的能够落地, 又会有多少商业价值? 比较容易想到的场景是工厂自动化, 
但是这些场景对 <strong>精度和节拍有高度的要求</strong>. 就算人型真的到了那一步, 能吃下工业场景的人形机器人肯定少之又少. 
更何况人形的复杂度极高, 出问题修复的成本也会非常高. 而一出问题, 产线停了. 后面的代价成本是非常大的.</p>
<p>But anyway, 具身智能一定是未来十年的趋势. 如何造出能够适配不同机器人的&quot;大脑&quot;与&quot;小脑&quot;是非常具有潜力的. 
市场上也有不少公司往机器人大脑发力. 按照目前的定义来看, 所谓&quot;大脑&quot;就是指机器人能够对环境感知以及具体任务的理解, &quot;小脑&quot;是负责具体的运动控制. 目前来看&quot;大脑&quot;基本都是基于VLM(Vision Language Model)去做的, &quot;大脑&quot;理解了具体的任务之后进行任务拆解, 然后交给&quot;小脑&quot;去执行. </p>
<p>比较容易想到的做法就是VLM输出对应的分解任务, 小脑根据收到的任务指令调用不同的行为树去执行. 这样落地是最快的方式, 我猜这也是工业界做demo肯定会采用的方式. 
这样做的好处是解释性比较高. 坏处是通用性比较差, 肯定不是最优解.</p>
<p>如果纯端到端的话, <strong>通用的机器人大小脑就会非常难做.</strong> 这里面的难度绝对不比自动驾驶的端到端低. 为什么会比自动驾驶端到端难做? 因为端到端需要将PNC给的输出提前当成输入, 比如自动驾驶的端到端就要把驾驶员的油门,转角,刹车当成输入, 至少2016年Nvidia在<a href="https://arxiv.org/pdf/1604.07316">&quot;End to End Learning for Self-Driving Cars&quot;</a>这里面就是这么做的. 有可能fsd v12用了别的黑魔法, 我这边不详细讨论因为没有调研就没有发言权. 回到正题, 此外模型受限于采集的传感器安装位置, 因此不同模型不具备通用性. 这就是很大的一个问题. 不同机器人的运动学模型不一样, 任务也不一样, 所以机器人小脑需要针对不同的机器人做适配. 目前来看, 不会像自驾一样能端到端解决所有问题. 机器人大小脑的结构应该会一直存在. </p>
<p>希望这一波做机器人大小脑的公司比如国外的<a href="https://www.skild.ai/">Sklid AI</a>以及国内的<a href="http://www.x2robot.com/">X Square Robot</a>能做出先进的成果. </p>
<p>剩下的文章部分是一些瞎扯关于我觉得人形机器人的落地路线.</p>
<p>Step1. 解决人形机器人的远程遥控问题. </p>
<p>Pro: 完成这一步可以远程演示demo拉融资, 美滋滋. </p>
<p>Con: 可惜最有价值的工业场景工厂是不会连外网的, 落地就gg了.</p>
<p>Step2. 解决人形机器人在特定场景的问题. 比如搬箱子, 分拣等.</p>
<p>Pro: 完成这一步能够吃下具体场景</p>
<p>Con: 在完成这一步之后, 不同厂商就会下沉到不同细分赛道. 所谓的通用机器人发现离落地还很远.</p>
<p>Step3: 完成人形机器人的仿真环境搭建, 云仿真, VR仿真等. </p>
<p>Pro: 能够在仿真环境直接验证不同的具体场景</p>
<p>Con: 仿真环境搭建难度比较大, 并且仿真环境需要和真实环境保持一致. 成本会非常高.</p>
<p>Step4: 发现原来人形的落地本质上是解决 <strong>如何在仿真环境里面快速验证原型方案的问题</strong> , 有的玩家开始研发仿真软件.</p>
<p>Pro: 能够完成这一步一定是行业领头羊了</p>
<p>Con: 没有利润</p>
<p>总之, 人形机器人一定需要有类似于联盟的组织, 一起发力去推动这件事才能有希望. 单独靠任何一个玩家去推动这件事, 成本都太高了.</p>

            
        </div>
        <div class="post-meta">
            
                


二〇二四年七月十七日

            
        </div>
    </article>
    

</section>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" integrity="sha512-894YE6QWD5I59HgZOGReFYm4dnWc1Qt5NtvYSaNcOP+u1T9qYdvdihz0PPSiiqn/+/3e7Jo4EaG7TubfWGUrMQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

    <script>
        var Home = location.href,
        xhr,
        xhrUrl = '';
    
        var Diaspora = {
            L: function(url, f, err) {
                if (url == xhrUrl) {
                    return false;
                }
                xhrUrl = url;
                if (xhr) {
                    xhr.abort();
                }
                xhr = $.ajax({
                    type: 'GET',
                    url: url,
                    timeout: 10000,
                    success: function(data) {
                        f(data);
                        xhrUrl = '';
                    },
                    error: function(a, b, c) {
                        if (b == 'abort') {
                            err && err()
                        } else {
                            window.location.href = url;
                        }
                        xhrUrl = '';
                    }
                });
            },
            loading: function() {
                var w = window.innerWidth;
                var css = '<style class="loaderstyle" id="loaderstyle'+ w +'">'+
                    '@-moz-keyframes loader'+ w +'{100%{background-position:'+ w +'px 0}}'+
                    '@-webkit-keyframes loader'+ w +'{100%{background-position:'+ w +'px 0}}'+
                    '.loader'+ w +'{-webkit-animation:loader'+ w +' 3s linear infinite;-moz-animation:loader'+ w +' 3s linear infinite;}'+
                    '</style>';
                $('.loaderstyle').remove()
                $('head').append(css)
                $('#loader').removeClass().addClass('loader'+ w).show()
            },
            loaded: function() {
                $('#loader').removeClass().hide()
            }
        };
    
        $(function() {
            $('body').on('click', function(e) {
                var tag = $(e.target).attr('class') || '',
                    rel = $(e.target).attr('rel') || '';
                if (!tag && !rel) return;
                switch (true) {
                    // next page
                    case (tag.indexOf('more') != -1):
                        tag = $('.more');
                        if (tag.data('status') == 'loading') {
                            return false
                        }
                        var num = parseInt(tag.data('page')) || 1;
                        if (num == 1) {
                            tag.data('page', 1)
                        }
                        tag.html("旧文").data('status', 'loading')
                        Diaspora.loading()
                        Diaspora.L(tag.attr('href'), function(data) {
                            tag.hide();
                            $('.license').hide();
                            var link = $(data).find('.more').attr('href');
                            if (link) {
                                tag.attr('href', link).html("旧文").data('status', 'loaded')
                                tag.data('page', parseInt(tag.data('page')) + 1)
                            }

                            var tempScrollTop = $(window).scrollTop();
                            $('body').append($(data).find('.posts'))
                            $(window).scrollTop(tempScrollTop + 100);
                            Diaspora.loaded()
                            //$('html,body').animate({ scrollTop: tempScrollTop + 400 }, 500);
                            if (link !== '/' && link != '') {
                                $('body').append($(data).find('.page-nav'))
                            }
                        }, function() {
                            tag.html("旧文").data('status', 'loaded')
                        })
                        return false;
                        break;
                    default:
                        return true;
                        break;
                }
            });
        })
    </script>
    
    <nav class="page-nav">
      <a href="https:&#x2F;&#x2F;evanlyu732.github.io&#x2F;page&#x2F;5&#x2F;" class="more">旧文</a>
    </nav>


    </main>
    
    <p class="license"></p>
    
</body>
</html>
