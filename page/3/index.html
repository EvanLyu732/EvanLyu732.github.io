<!DOCTYPE html>
<html>
<head>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>


    
        <link rel="alternate" type="application/rss+xml" title="RSS" href="https://evanlyu732.github.io/atom.xml">
    
    
    
        
    
    
    
    
    
    
        
    
    
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
    <title>evan lyu</title>
    <meta charset="utf-8">
    <meta name="title" content="evan lyu">
    <meta name="description" content="">
    <meta property="og:image:width" content="200" />
    <meta property="og:image:height" content="200" />
    <link rel="stylesheet" href="https:&#x2F;&#x2F;evanlyu732.github.io/style.css">
    
    
    <style>
    @media screen and (min-width: 320px) {
        body {
            font-size: calc(16px + 2 * ((100vw - 320px) / 960));
        }
    }
    </style>
    
    <link rel="stylesheet" href="https://fonts.loli.net/css2?family=Source+Serif+Pro:wght@400;700&display=swap">
    <link rel="stylesheet" href="https://fonts.loli.net/css2?family=Noto+Serif+SC:wght@400;700&display=swap">
    <style>body { font-family: 'Source Serif Pro', 'Source Han Serif SC', 'Noto Serif CJK SC', 'Noto Serif SC', serif }</style>
    
</head>
<body>
    
    <header class="header">
        <div class="blog-title"><a href="https:&#x2F;&#x2F;evanlyu732.github.io" class="logo">evan lyu</a></div>
        <nav class="navbar">
    <ul class="menu">
        
        
        <li class="menu-item">
            
            
            
            
            <a href="https:&#x2F;&#x2F;evanlyu732.github.io&#x2F;" class="current-menu-item-link">主页</a>
            
        </li>
        
        <li class="menu-item">
            
            
            
            
            <a href="https:&#x2F;&#x2F;evanlyu732.github.io&#x2F;archives" class="menu-item-link">归档</a>
            
        </li>
        
        <li class="menu-item">
            
            
            
            
            <a href="https:&#x2F;&#x2F;evanlyu732.github.io&#x2F;about" class="menu-item-link">关于</a>
            
        </li>
        
        <li class="menu-item">
            
            
            
            
            <a href="https:&#x2F;&#x2F;evanlyu732.github.io&#x2F;note" class="menu-item-link">书架</a>
            
        </li>
        
        <li class="menu-item">
            
            
            
            
            <a href="https:&#x2F;&#x2F;evanlyu732.github.io&#x2F;atom.xml" class="menu-item-link">订阅</a>
            
        </li>
        
    </ul>
</nav>

    </header>
    
    <main class="main">
        
<section class="posts">
    
    <article class="post">
        <div class="post-title"><a href="https:&#x2F;&#x2F;evanlyu732.github.io&#x2F;blog33&#x2F;" class="post-title-link">深度强化学习101</a></div>
        <div class="post-content">
            
                <p>记录一下接触深度强化学习的学习历程. 材料选自Pieter Abbeel的<a href="https://www.youtube.com/watch?v=2GwBez0D20A">Foundation of Deep RL Series.</a>. 整篇文章追求知识点的连惯性. 所以会补充详细的公式和历史背景. 这篇文章会一直持续更新. 也算是对之前说要写的llya30做一次原型测试吧. 由于会采用不用来源的资料所以概念会有重叠, 好处是可以从不同角度看到一个概念的描述. 方便更全面的理解.</p>
<h2 id="mu-lu">目录</h2>
<ul>
<li><a href="https://evanlyu732.github.io/blog33/#foundations-of-deep-reinforcement-learning-with-pieter-abbeel">Foundations of Deep Reinforcement Learning with Pieter Abbeel</a>
<ul>
<li><a href="https://evanlyu732.github.io/blog33/#lecture-1-mdps-exact-solution-methods-max-ent-rl">Lecture 1: MDPs, Exact Solution Methods, Max-ent RL</a></li>
<li><a href="https://evanlyu732.github.io/blog33/#lecture-2-deep-q-learning">Lecture 2: Deep Q-Learning</a></li>
<li><a href="https://evanlyu732.github.io/blog33/#lecture-3-policy-gradients-advantage-estimation">Lecture 3: Policy Gradients, Advantage Estimation</a></li>
<li><a href="https://evanlyu732.github.io/blog33/#lecture-4-trpo-ppo">Lecture 4: TRPO, PPO</a></li>
<li><a href="https://evanlyu732.github.io/blog33/#lecture-5-ddpg-sac">Lecture 5: DDPG, SAC</a></li>
<li><a href="https://evanlyu732.github.io/blog33/#lecture-6-model-based-rl">Lecture 6: Model-based RL</a></li>
</ul>
</li>
<li><a href="https://evanlyu732.github.io/blog33/#cs-285deep-reinforcement-learning">CS 285:Deep Reinforcement Learning</a></li>
<li><a href="https://evanlyu732.github.io/blog33/#ucl-course-on-rl">UCL Course on RL</a></li>
<li><a href="https://evanlyu732.github.io/blog33/#%E9%A1%B9%E7%9B%AE">项目</a></li>
<li><a href="https://evanlyu732.github.io/blog33/#where-to-go-next">Where to Go Next?</a></li>
</ul>
<p><a id="foundations-of-deep-reinforcement-learning-with-pieter-abbeel"></a></p>
<h1 id="foundations-of-deep-reinforcement-learning-with-pieter-abbeel">Foundations of Deep Reinforcement Learning with Pieter Abbeel</h1>
<p><a id="lecture-1-mdps-exact-solution-methods-max-ent-rl"></a></p>
<h2 id="lecture-1-mdps-exact-solution-methods-max-ent-rl">Lecture 1: MDPs, Exact Solution Methods, Max-ent RL</h2>
<p>点击<a href="https://www.dropbox.com/scl/fi/rvbpc40ozhstnwhk7h5b7/l1-mdps-exact-methods.pdf?rlkey=5bibe5t8cqmpm9dhth969iiq6&amp;e=1&amp;dl=0">这里</a>进入lecture1的slides. 一句话总结lecture1的内容: 强化学习可以表示为马尔可夫决策过程(Markov Decision Processes, MDPs). 解MDP有两种基本策略, Value Iteration和Policy Iteration. 另外, 引入Entropy带MDP可以提升MDP的鲁棒性.</p>
<ul>
<li>
<p>MDP: 需要了解什么是MDP. 先要了解什么是马尔可夫链(Markov chain). Markov为了证明独立同分布不是大数定律(Law of large numbers)满足的前提, 在1906年发表的文章里面提出了马尔可夫链(Markov chain). 如果需要进一步了解Markov chain, 推荐这个<a href="https://www.youtube.com/watch?v=CIe869Rce2k">视频</a></p>
<ul>
<li>Markov chain: 前提下一颗的状态 只取决于当前时刻 ,转移矩阵 </li>
<li>frist-order Markov chain &amp; n-order Markov chain:</li>
<li>Markov chains convergence: 我们在前面说到了Markov chain的提出是为了证明大数定律在非独立同分布的假设前提下, 依然成立. 那么Markov chain是如何收敛的呢?</li>
</ul>
</li>
</ul>
<p>$$
\frac{n!}{k!(n-k)!} = \binom{n}{k}
$$</p>
<ul>
<li>
<p>Bellman equation: </p>
</li>
<li>
<p>Value Iteration:</p>
</li>
<li>
<p>Policy Iteration:</p>
</li>
<li>
<p>Maximum Entropy Formulation:</p>
</li>
</ul>
<p>我们这里通过slide里面的grid world并结合代码来理解一下整个过程.</p>
<ul>
<li>小结:</li>
</ul>
<p><a id="lecture-2-deep-q-learning"></a></p>
<h2 id="lecture-2-deep-q-learning">Lecture 2: Deep Q-Learning</h2>
<p>点击<a href="https://www.dropbox.com/scl/fi/rvbpc40ozhstnwhk7h5b7/l1-mdps-exact-methods.pdf?rlkey=5bibe5t8cqmpm9dhth969iiq6&amp;e=1&amp;dl=0">这里</a>进入lecture2的slides. 一句话总结lecture2的内容: 由于实际情况下MDP的状态空间通常很大, 不适合直接用value iteration和policy iteration来解复杂的MDP. Q-Learning通过在样本空间进行采样来解复杂的MDP. 而Q-Learning也需要表格存储状态转移信息. DQN通过使用神经网络去采样来近似Q函数.</p>
<ul>
<li>
<p>Q-Learning:</p>
</li>
<li>
<p>DQN:</p>
</li>
</ul>
<p><a id="lecture-3-policy-gradients-advantage-estimation"></a></p>
<h2 id="lecture-3-policy-gradients-advantage-estimation">Lecture 3: Policy Gradients, Advantage Estimation</h2>
<p>点击<a href="https://www.dropbox.com/scl/fi/htn2r6ac807oluoxeihdt/l3-policy-gradient-and-advantage-estimation.pdf?rlkey=26hsbd5qvthb8ozq53vdfjrr4&amp;e=1&amp;dl=0">这里</a>进入lecture3的slides. 一句话总结lecture3的内容: 由于Value Iteration无法表示下一步的动作, 并且Q-learning在高维空间下没办法有效求解. 相比与Value Iteration和Q-learning, Policy Gradients的表示更加简单. 而Policy Gradients通过Likelihood Ratio Graident求解出来的是Path. 需要使用Temporal decomposition分解成State和Action. 需要使用Baseline subtraction去改变最终选择的Path. 在使用公式去分解的时候, 需要使用Value function estimation求解. 而在Advantage Estimation介绍一些更加进阶的Value function estimation方法.</p>
<ul>
<li>Policy Gradients:</li>
<li>Temporal Decomposition:</li>
<li>Baseline subtraction:</li>
<li>Value function estimation:</li>
<li>Advantage Estimation(A2C/A3C/GAE):</li>
</ul>
<p><a id="lecture-4-trpo-ppo"></a></p>
<h2 id="lecture-4-trpo-ppo">Lecture 4: TRPO, PPO</h2>
<p>点击<a href="https://www.dropbox.com/scl/fi/z0ev7f53yoyilrkfl9jck/l4-TRPO-PPO.pdf?rlkey=1y8f0am0bpqyxysxq3adnkobu&amp;e=1&amp;dl=0">这里</a>进入lecture4的slides. 一句话总结lecture4的内容: 在Lecture 3中, 我们知道Policy Gradients可以求解出特定的Path. 但是在求解特定的Path的过程中, 步长(step-size)的大小该如何确定呢? TRPO解决了这个问题. 而TRPO需要second order来求解, 而不太方便做优化. PPO作为TRPO的改进, 降阶为first-order优化问题.</p>
<ul>
<li>Surrogate loss: </li>
<li>Step-sizing and Trust Region Policy Optimization (TRPO):</li>
<li>Proximal Policy Optimization (PPO):</li>
</ul>
<p><a id="lecture-5-ddpg-sac"></a></p>
<h2 id="lecture-5-ddpg-sac">Lecture 5: DDPG, SAC</h2>
<p>点击<a href="https://www.dropbox.com/scl/fi/302ef41a9929yvtedc77l/l5-DDPG-SAC.pdf?rlkey=xc21zgliwfjynjse1je8oo6mx&amp;dl=0">这里</a>进入lecture5的slides. 一句话总结lecture5的内容: 对于特定场景, on-policy方法采样复杂度会比较高. 而DDPG解决了这个问题. SAC通过引入entropy保证了更好的收敛和防止过拟合.</p>
<ul>
<li>Deep Deterministic Policy Gradient (DDPG):</li>
<li>Soft Actor Critic (SAC):</li>
</ul>
<p><a id="lecture-6-model-based-rl"></a></p>
<h2 id="lecture-6-model-based-rl">Lecture 6: Model-based RL</h2>
<p>点击<a href="https://www.dropbox.com/scl/fi/pnv0k74lbajh2uahoegwr/l6-model-based-rl.pdf?rlkey=psemgw6b6a4c4owmc16liyba0&amp;dl=0">这里</a>进入lecture6的slides. 一句话总结lecture6的内容: 前面5个lecture讲的都是model-free RL. 所谓model-free RL是指agent直接通过action来迭代policy而不需要学习环境.  model-based RL通过对环境建模再进行policy迭代.</p>
<ul>
<li>Model-based RL:</li>
<li>Robust Model-based RL:Model-EnsembleTRPO (ME-TRPO):</li>
<li>Adaptive Model-based RL: Model-based Meta-Policy Optimization (MB-MPO):</li>
</ul>
<p><a id="cs-285deep-reinforcement-learning"></a></p>
<h1 id="cs-285-deep-reinforcement-learning">CS 285:Deep Reinforcement Learning</h1>
<p>这一部分采用CS 285来补充一下上一部分没提到的一些内容.</p>
<p><a id="ucl-course-on-rl"></a></p>
<h1 id="ucl-course-on-rl">UCL Course on RL</h1>
<p><a id="项目"></a></p>
<h1 id="xiang-mu">项目</h1>
<p><a id="where-to-go-next"></a></p>
<h1 id="where-to-go-next">Where to Go Next?</h1>

            
        </div>
        <div class="post-meta">
            
                


二〇二四年九月三日

            
        </div>
    </article>
    
    <article class="post">
        <div class="post-title"><a href="https:&#x2F;&#x2F;evanlyu732.github.io&#x2F;blog32&#x2F;" class="post-title-link">智力复利</a></div>
        <div class="post-content">
            
                <p>最近在重新回顾Naval写的书, 在网页版的最后Naval推荐了一系列读物. 其中有一个<a href="https://x.com/zaoyang/status/940409514875961344">twitter thread</a>是Naval标记是Must Read. 之前一直没注意到.
看了一遍有点感触. 这篇文章是这篇twitter thread的原文集合. 原文在<a href="https://x.com/zaoyang/status/940409514875961344">这里</a>. (Twitter thread on “intellectual compounding” by @Zaoyang)</p>
<p>1/ There's a concept known as financial compounding, but most people don't know about intellectual compounding. Buffett and Munger employed this to great effect and to accumulate mental models such that they can make large decisions quickly. Intuition is simply reading a lot.</p>
<p>2/ This allows people to convert typically slow thinking and bad fast thinking (bad intuition) into good intuition. In academic literature this is known as Type 1 and Type 2 thinking. Most people don't accumulate enough of knowledge the tree.</p>
<p>3/ One of the common patterns for a self made billionaires is their ability to self study, self reason and accumulate a set of their own mental model. Intellectual capital compounds at a hidden rate and most people use tangible badges and net worth as measures.</p>
<p>4/ Intellectual capital is filling out the decision tree and is a forward looking view and net worth is backward looking. Just like how the wrong way to value tech companies with network effects is revenue but instead by their retention rate and network effects.</p>
<p>5/ Most people value themselves on their individual badges, which is what society labels for you. But most of what is predictive in life, is how you make decisions. Being effective and investing your time in the right area at the right time is a skill, not purely luck.</p>
<p>6/ Allowing readings to fill your mind takes advantage of your diffuse/focused mode of thinking and type 1 and type 2 decision making. Meaning you can focus and use your creative brain (diffuse mode) to wander and make associations. This is the key toward STEM education.</p>
<p>7/ More and more, just like the last 20 years was focused on physical athletes, the next 20 years would be focused on mental atheletes. These ways of thinking and compounding, Buffett, Munger, and polymaths have already used to a large degree and have been confirmed by academia.</p>
<p>8/ As the world get faster and faster with AR/VR, AI, crypto. The ability to invest in your own intellectual capital is a crucial prerequisite to maintaining and succeeding in this world and also for your children.</p>
<p>9/ While politicians say it's education that's important, it's only partially true, it's the ability to assimilate knowledge trees and compound knowledge that leads to satisfaction, mental stimulation, and long term wealth.</p>
<p>10/ What politicians are doing now is simply aiming backwards, but how can you scale this to everyone? It turns out that charter school have been doing a grand experiment.</p>
<p>11/ Taking children from disadvantaged backgrounds and making them fit for college. This has worked and three of the results are the following.</p>
<p>12/ &quot;Growth mindset&quot; not &quot;Fixed mindset&quot; &quot;Motivation mindset&quot; not &quot;Fixed mindset&quot; &quot;Student directed AND teacher directed education and projects&quot;</p>
<p>13/ In turns out statistically those three items are the most predictive. What are they? I'm glad you asked.</p>
<p>14/ It turns out that if you just tell students that their mind is like a &quot;muscle&quot; and spend just 10 minutes explaining that concept they will improve their grades dramatically.</p>
<p>15/ It turns out this concept is for a person's mind and for each skill set. People can have verbal &quot;fixed&quot; mindsets, humor &quot;fixed&quot; mindsets, math &quot;fixed&quot; mindsets. Almost everything. So, you have to consciously unlearn this and apply it consciously even if you know it.</p>
<p>16/ Why is this? It turns out people are criticized by society and labeled. So even if you have a &quot;growth&quot; mindset for physical items, you don't have it for mental items. This applies not only for students but also for adults. You always hear &quot;That's not me.&quot; It's a label.</p>
<p>17/ There's another concept called &quot;motivational mindset&quot; which teaches the person &quot;what good looks like&quot; which simply teaches the kid to follow &quot;go do the extra problems&quot; &quot;go to office hours&quot; &quot;do more problems&quot; Follow the process of the &quot;motivated student&quot; and it will work.</p>
<p>18/ It turns out these two concepts turn someone that's socio economically disadvantaged similar to the education status of someone who grew up upper middle class. This is not a panacea as a lot of people have so much stressors in their lives that they can't study.</p>
<p>19/ The last concept is student self directed project plus teacher lectures is the best. This surprised me, but conceptually, it gives the student agency and motivation. Most students have been so battered down by the system that they can't do this, but that's another story.</p>
<p>20/ These concepts have to be mind beliefs. Just like in Dune how they cite &quot;fear is the mindkiller&quot; These concepts have to be constantly applied to adults and children as they opposite tends to be pervasive and insidious.</p>
<p>21/ These are mindsets and as for strategies. People need to take concepts from Learning how to Learn by <a href="https://x.com/BarbaraOakley">@barbaraoakley</a> and <a href="https://x.com/sejnowski">@sejnowski</a>
and Art of Learning from Josh Waitzkin. They are are a manual for your brain.</p>
<p>22/ You thought just because you own a brain you knew how to operate it right? Why do you think the drop out rates for STEM is so high. Most people attribute it to pipeline or professor, but perhaps it's because people don't know how to learn difficult subjects.</p>
<p>23/ @LHTL_MOOC takes you from beginner to intermediate, and art of learning takes you from expert to being world class. Then you have Cal Newport's material, and those three resources are simply the best that I know of to hack your own brain</p>
<p>24/ Do you know anymore? Would love to know more resources and techniques.</p>
<p>25/ In conclusion, as the world become more and more technical and complex, most people don't have the mindset nor tactical skills. In short, people have to re-learn the manual to their own brain. Just because you have a computer, it doesn't mean you know everything about it.</p>

            
        </div>
        <div class="post-meta">
            
                


二〇二四年八月五日

            
        </div>
    </article>
    
    <article class="post">
        <div class="post-title"><a href="https:&#x2F;&#x2F;evanlyu732.github.io&#x2F;blog30&#x2F;" class="post-title-link">读毛泽东武略</a></div>
        <div class="post-content">
            
                <p>这几天花了点时间读完<a href="https://book.douban.com/subject/1203879/">毛泽东武略</a>, 一共大概500页内容不算太长. 之所以会去读这本书是因为如果长时期接触技术方面的内容, 其他方面的视野不可避免的受限. 这本书有很多思想其实对做事很有帮助.</p>
<p>(1) 原文: &quot;毛泽东从自己的经验总结道: &quot;不要迷信军事科学, 只要去打仗, 一点也不难学会. &quot;</p>
<p>思考: 我们从小接受的教育就是阅读书A, 读完了A, 你通过考试来验证你对A的理解. 现实生活当中往往问题是开放多元的. 因此, 我们有时会陷入<a href="https://www.reddit.com/r/learnprogramming/comments/qrlx5m/what_exactly_is_tutorial_hell/?rdt=59004">教程地狱(Tutorial Hell)</a>. 即观看学习书籍, 以为看完了记下来所有知识就有用, 但是放到实际问题当中却无法生效. 从而回头继续观看学习书籍, 一种反复循环的模式.
我想到了之前Geo Hotz在<a href="https://www.youtube.com/watch?v=-v8pD0d5Bmk">How not to be a noob</a>说的. &quot;If you think like a noob, you always gonna be a noob.&quot; 思考的框架会制约了行动模式. 什么意思? 我们接触一个新领域往往因为我们是菜鸟会认为我们需要先验的背景知识之后, 才能去做事. 往往过度高估了事情失败的风险, 却低估了这种模式(通过快速失败和迭代)的有效性. 知道什么方向值得去做, 什么问题值得去解决. 如何在未知的方向下找到合适的落脚点并进行拆解任务才是更有价值的. </p>
<p>(2) 原文: &quot;战略, 战役和战斗是三个不同的概念. 在这三个概念中, 战略是最高层次, 战斗是最低层次, 战役则是中间层次. 但战役中也有属于战略范畴的, 如战略决战. 在这些层次中, 战略是主导. &quot;在主力红军与游击队的矛盾中, 主力红军是主导. 在进攻战术与防御战术的矛盾中, 进攻是主导. 在战略与战术的矛盾中, 战略是主导.&quot;</p>
<p>思考: 计划的实施决定最后的成果, 但是在这之前有个更重要的问题. 如何制定计划以及为什么这么制定计划? 如何在实施的过程中动态调整计划?. 自我反思我是花在计划的时间上太少, 要制定好的计划就需要有调查研究. 我在很多时候做决策就像贪心算法一样, 希望局部最优能让全局最优. 但是这样往往在大方向上却欠佳, 并且也无法让阶段性的成果就像滚雪球一样积累起来.</p>
<p>(3) 原文: &quot;因此, 战争指导者的责任是将自己的注意力放在战略上, 放在他主持的全局上. 用毛泽东的话说, 就是只有了解大局的人才能合理而恰当地处置小的东西, 即使当个排长也应该有全局的图画. 他形象地说: 没有战略, 战术也一定谈不好. 小的东西是要占大的东西的地位的, 如一个鼻子, 你能把它安在背上吗? 抗战初期在延安, 毛泽东反复讲要&quot;提高战略空气&quot;. 纵观中国革命战争中的政我双方, 在战略战术上是呈相反趋势的: 在战术行动上, 敌军也许并不逊色, 但在战略指导上, 则远不如入民军队. &quot;</p>
<p>思考: 选择大于努力, 要做出好的选择一是要有认识, 二是要有勇气. 因为最优的选择有时候需要放弃短期的利益, 并且去做常理相反的事情才有可能达成. 一股脑的扎进努力和不去努力都是不可取的. 需要锻炼在宏观和微观的视角上来回切换的能力.</p>
<p>(4) 原文: &quot;战略上的有规则有定向, 战役战斗上的不规则无定向.&quot;</p>
<p>思考: 在大的计划上必须是清晰的并且不能随意变动, 因为不清晰意味着无法实现, 随意变动意味着无法积累. 但在局部的执行细节上, 由于外界因素的变化需要动态调整.</p>
<p>(5) 原文: &quot;在一个时期内, 战略方向是相对固定的, 而且只能有一个. 在一个时期内不能允许有两个帮至多个战略方向. &quot;在有强大敌军存在的条件下, 无论自己有多少军队, 在一个时间内, 主要的使用方向只应有一个, 不应有两个. 我不反对作战方向有两个或两个以上, 但主要的方向, 在同一个时间内, 只应有一个. &quot;</p>
<p>思考: 集中资源和注意力完成一个清晰的目标. 当一个阶段性的目标完成之后，再去攻克下一个目标. 同时开展很多项目只会让资源得到分散并且得到收益的时间会被拉长. 很多认知只有在执行的过程中才会形成. </p>
<p>(6) 原文: &quot;抓战略, 主要是抓两点, 一是抓主动权, 二是抓战略方向. 清人王欠佑在&quot;乾坤大略&quot;中说, 战略方向的选定, 是用兵成败
的关键, &quot;霜王大略, 此其首侨.&quot; 毛泽东抓住了这个&quot;霸王大略&quot;, 在实践中灵活加以运用. 研究毛泽东的战略战术思想, 可以发现毛泽东对具体的
布阵, 并不很费心, 但以极大的精力关注战略方向的选择.&quot;</p>
<p>思考: 我理解的主动权是能不能通过时间获得积累. 因为对于普罗大众来说, 时间即是朋友也是敌人. 一方面, 社会以及企业会希望有匹配工作年限的能力. 另一方面，当处于一个固定不变的环境的时候, 工作能力是不可能得到明显的锻炼的. 只有做出合适的选择才会让人享受到时间的复利. 有时候选择需要在框架之外才能实现.</p>
<p>(7) 原文: &quot;毛泽东在中国革命战争中有许多独到的见解和创造, 其中战略主动权和战役战斗主动权(以下均作战役主动权)概念的提出即为其中之一. 毛泽东将主动权按层次划分为战略主动权和战役战斗权. 战略主动权是军队在战争全局上的自由地位, 战役主动权是军队在局部和一定程度上的自由地位. &quot;</p>
<p>思考: 接着上一条说, 战略主动权是指宏观上的选择是否能享受时间的复利. 战役主动权是指在细节的执行上不会受到外界因素过大的干扰, 导致行为不符合最开始执行的战略. 假如遇到了这种情况. 我认为会有两种原因, 一是最开始战略制定的时候忽视了过多因素, 这种情况下是战略制定的不恰当. 另一种情况则是执行层执行的时候没有正确符合战略层的规划. 说起来容易做起来很难. 需要训练反复切换思维的能力.</p>
<p>(8) 原文: &quot;以局部优势达成全局优势, 以战役战术主动赢得战略主动. 劣势军队只要不是绝对劣势, 就可以通过正确的主观指导, 通过局部的优势和主动, 逐渐造成战略的优势和战略的主动地位.&quot;</p>
<p>思考: 客观来说处于弱势的一方只能通过花更多时间在细节上打磨才能追上优势一方. 但是在执行的过程中很容易陷入努力陷阱，好的任务拆解以及好的策略才是最核心的事情.</p>
<p>(9) 原文: &quot;调查不够不决策, 条件不备不行动.&quot;</p>
<p>思考: 与汉明说的其实是一致，在工程上如果去做花很大的成本去做自己不懂的事情. 就是搬起石头砸脚. 只有很好的观察力才知道什么条件因素是关键, 锻炼观察力需要抛弃先验. 过于依赖先验是无法学习新的东西. </p>
<p>(10) 原文: &quot;战争指导的一条重要原则, 是力避和被动, 力争主动, 这是军队获得行动自由, 争取战争胜利的根本条件. &quot;</p>
<p>思考: 主动与被动其实这是一个观察因素, 比如人际交往, 做事情. 主动才有机会. 主动才能创造出现实. 而不是沉默是金, 过于沉默只会埋没自己的声音. </p>
<p>(11) 原文: &quot;打”与“走”, 两个字, 确实简单明了, 但里面却有着丰富的内涵. 中国革命战争几乎所有的战役战斗都包含着走和打两个过程. &quot;打得赢就打,打不赢就二&quot;, 说的就是&quot;走&quot;与&quot;打&quot;的关系. 毛泽东有一名名言:&quot;不要把干粮线丢掉了.&quot;. 说的就是随时准备走. 在走和打的关系上, 光走不打是逃跑主义, 光打不走是拼命主义.&quot;</p>
<p>思考: 打与走的关系在我们的生活中非常深刻. 比较明显的表现在于过于执着于牛角尖. 作为工程师钻研精神绝对是一个非常重要的品质. 但是知道什么问题可以跳过, 什么资源可以更快的完成事情的能力更加重要.</p>
<p>(12) 原文: &quot;正确处理弃守地方与歼灭敌人的关系, 是战争指导者首先碰到并无法回避的问题. 军事教条主义者总是希望多占土地, &quot;多敌
于国门之外&quot;, 主观愿望很好, 但结果往往是人地两失. 守地必分散
兵力. 处处防守, 必处处挨打.&quot;</p>
<p>思考: 多占土地可以理解为占领更多短期资源. 但是要取得长期最大收益, 有时候需要放弃短期利益. 灵活处理问题, 放弃教条主义.</p>

            
        </div>
        <div class="post-meta">
            
                


二〇二四年八月二日

            
        </div>
    </article>
    

</section>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" integrity="sha512-894YE6QWD5I59HgZOGReFYm4dnWc1Qt5NtvYSaNcOP+u1T9qYdvdihz0PPSiiqn/+/3e7Jo4EaG7TubfWGUrMQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

    <script>
        var Home = location.href,
        xhr,
        xhrUrl = '';
    
        var Diaspora = {
            L: function(url, f, err) {
                if (url == xhrUrl) {
                    return false;
                }
                xhrUrl = url;
                if (xhr) {
                    xhr.abort();
                }
                xhr = $.ajax({
                    type: 'GET',
                    url: url,
                    timeout: 10000,
                    success: function(data) {
                        f(data);
                        xhrUrl = '';
                    },
                    error: function(a, b, c) {
                        if (b == 'abort') {
                            err && err()
                        } else {
                            window.location.href = url;
                        }
                        xhrUrl = '';
                    }
                });
            },
            loading: function() {
                var w = window.innerWidth;
                var css = '<style class="loaderstyle" id="loaderstyle'+ w +'">'+
                    '@-moz-keyframes loader'+ w +'{100%{background-position:'+ w +'px 0}}'+
                    '@-webkit-keyframes loader'+ w +'{100%{background-position:'+ w +'px 0}}'+
                    '.loader'+ w +'{-webkit-animation:loader'+ w +' 3s linear infinite;-moz-animation:loader'+ w +' 3s linear infinite;}'+
                    '</style>';
                $('.loaderstyle').remove()
                $('head').append(css)
                $('#loader').removeClass().addClass('loader'+ w).show()
            },
            loaded: function() {
                $('#loader').removeClass().hide()
            }
        };
    
        $(function() {
            $('body').on('click', function(e) {
                var tag = $(e.target).attr('class') || '',
                    rel = $(e.target).attr('rel') || '';
                if (!tag && !rel) return;
                switch (true) {
                    // next page
                    case (tag.indexOf('more') != -1):
                        tag = $('.more');
                        if (tag.data('status') == 'loading') {
                            return false
                        }
                        var num = parseInt(tag.data('page')) || 1;
                        if (num == 1) {
                            tag.data('page', 1)
                        }
                        tag.html("旧文").data('status', 'loading')
                        Diaspora.loading()
                        Diaspora.L(tag.attr('href'), function(data) {
                            tag.hide();
                            $('.license').hide();
                            var link = $(data).find('.more').attr('href');
                            if (link) {
                                tag.attr('href', link).html("旧文").data('status', 'loaded')
                                tag.data('page', parseInt(tag.data('page')) + 1)
                            }

                            var tempScrollTop = $(window).scrollTop();
                            $('body').append($(data).find('.posts'))
                            $(window).scrollTop(tempScrollTop + 100);
                            Diaspora.loaded()
                            //$('html,body').animate({ scrollTop: tempScrollTop + 400 }, 500);
                            if (link !== '/' && link != '') {
                                $('body').append($(data).find('.page-nav'))
                            }
                        }, function() {
                            tag.html("旧文").data('status', 'loaded')
                        })
                        return false;
                        break;
                    default:
                        return true;
                        break;
                }
            });
        })
    </script>
    
    <nav class="page-nav">
      <a href="https:&#x2F;&#x2F;evanlyu732.github.io&#x2F;page&#x2F;4&#x2F;" class="more">旧文</a>
    </nav>


    </main>
    
    <p class="license"></p>
    
</body>
</html>
