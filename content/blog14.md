
+++
title = "从零开始跟着Ilya Sutskever掌握90%的人工智能"
date = 2024-06-26
+++

[John Carmack](https://en.wikipedia.org/wiki/John_Carmack)让[Ilya Sutskever](https://en.wikipedia.org/wiki/Ilya_Sutskever)推荐关于了解当下人工智能的阅读资料. Ilya Sutskever给了大约有40篇研究论文的链接.

>  If you really learn all of these, you’ll know 90% of what matters today. -  Ilya Sutskever
>
>  如果你真的学会了这些，你就掌握了当今90%重要的内容 - Ilya Sutskever

大概在一个月以前, [推特](https://x.com/keshavchan/status/1787861946173186062)上流传一份[文件夹](https://arc.net/folder/D0472A20-9C20-4D3F-B145-D2865C0A9FEE)包含30篇资料(论文, 书籍, 博客)包含了这些资料.

<img src="https://raw.githubusercontent.com/EvanLyu732/evanlyu732.github.io/main/static/images/30u30.png" height="50" width="50"/>

# 阅读列表

按照发布的时间线从旧到新排列如下:

| <div style="width:290px">Time</div> | Paper |
|------|-------|
| 1993 | [Keeping Neural Networks Simple by Minimizing the Description Length of the Weights](https://www.cs.toronto.edu/~hinton/absps/colt93.pdf) |
| 2004 | [A Tutorial Introduction to the Minimum Description Length Principle](https://arxiv.org/pdf/math/0406077) |
| 2008 | [Machine Super Intelligence](https://www.vetta.org/documents/Machine_Super_Intelligence.pdf) |
| 2011 | [The First Law of Complexodynamics](https://scottaaronson.blog/?p=762) |
| 2012 | [ImageNet Classification with Deep Convolutional Neural Networks](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf) |
| 2014 | [Quantifying the Rise and Fall of Complexity in Closed Systems: The Coffee Automaton](https://arxiv.org/pdf/1405.6903) |
| 2014 | [Neural Turing Machines](https://arxiv.org/pdf/1410.5401) |
| 2015 | [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) |
| 2015 | [Understanding LSTM Networks](https://arc.net/folder/D0472A20-9C20-4D3F-B145-D2865C0A9FEE) |
| 2015 | [Recurrent Neural Network Regularization](https://arxiv.org/pdf/1409.2329) |
| 2015 | [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385) |
| 2015 | [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/pdf/1409.0473) |
| 2015 | [Deep Speech 2: End-to-End Speech Recognition in English and Mandarin](https://arxiv.org/pdf/1512.02595) |
| 2016 | [Order Matters: Sequence to Sequence for Sets](https://arxiv.org/pdf/1511.06391) |
| 2016 | [Multi-Scale Context Aggregation by Dilated Convolutions](https://arxiv.org/pdf/1511.07122) |
| 2016 | [Identity Mappings in Deep Residual Networks](https://arxiv.org/pdf/1603.05027) |
| 2017 | [Pointer Networks](https://arxiv.org/pdf/1506.03134) |
| 2017 | [Neural Message Passing for Quantum Chemistry](https://arxiv.org/pdf/1704.01212) |
| 2017 | [Attention Is All You Need](https://arxiv.org/pdf/1706.03762) |
| 2017 | [A simple neural network module for relational reasoning](https://arxiv.org/pdf/1706.01427) |
| 2017 | [Variational Lossy Autoencoder](https://arxiv.org/pdf/1611.02731) |
| 2017 | [Kolmogorov Complexity and Algorithmic Randomness](https://www.lirmm.fr/~ashen/kolmbook-eng-scan.pdf) |
| 2018 | [Relational Recurrent Neural Networks](https://arxiv.org/pdf/1806.01822) |
| 2019 | [GPipe: Easy Scaling with Micro-Batch Pipeline Parallelism](https://arxiv.org/pdf/1811.06965) |
| 2020 | [Scaling Laws for Neural Language Models](https://arxiv.org/pdf/2001.08361) |
| 2022 | [The Annotated Transformer](https://nlp.seas.harvard.edu/annotated-transformer/) |
| 2024 | [CS231n: Convolutional Neural Networks for Visual Recognition](https://cs231n.github.io/) |


# 计划

写30篇文章深度解析Ilya推荐的每一份资料, 并深度实践每一篇资料的概念.


# 为什么要做这个事

* 现在关于贩卖人工智能焦虑的文章越来越多. 真正有价值的文章都会有特定阅读群体. 这个系列定位是所有人. 
* 互联网上的信息总是零散的多, 能够串联起来形成完成的线的文章少. 
* 中文互联网需要更多有价值的内容, 我认为这个过程是有价值的. 
* 对自己来说也是一个学习的过程, 检验自己是否真的理解. 任何经不起质疑的观点都是错的.

## 前提
虽然说是从零, 但是不会包括编程的教学.
* 需要能够基本使用Python.
* 有一定英文阅读能力

## 结果

看完这30篇文章并实践之后, 你能够:

* 了解每一个篇文章提出的背景, 定义, 原理, 实现, 应用.
* 能够通过代码实现每一个步骤, 并能论证作者的推理. 每一篇文章都会有对应的Jupter Notebook.
* 按照时间线理解30篇文章, 所以会知道发展的脉络. 对未来的发展方向会有更清晰的理解.
* 按照Ilya说的, 能够理解90%的人工智能.


# 相关链接

* [Ilya Sutskever's Top 30](https://aman.ai/primers/ai/top-30-papers/)
* [Ilya’s AI papers: Key Takeaways](https://mfaulk.github.io/2024/06/19/ilya-papers.html)










